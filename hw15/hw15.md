* 1.  list all of the new annotations you learned to your annotations.md
      API Gateway - Zull/Zull2/Spring Cloud Gateway
      @EnableZuulProxy: Annotation to enable Zuul proxy.
      @EnableZuulServer: Annotation to enable Zuul server.
      @EnableSpringCloudGateway: Annotation to enable Spring Cloud Gateway.

* 2.  Document the microservice architeture and components/tools/dependencies
      It splits one large application into multiple small and independent service based applications
      API Gateway:
      Responsible for handling client requests and routing them to the appropriate microservices.
      Examples: Zuul, Spring Cloud Gateway.
      Service Discovery:
      Enables services to find and communicate with each other without direct dependencies.
      Load Balancer:
      Distributes incoming network traffic across multiple servers to ensure no single server is overwhelmed.
      Database:
      Each microservice can have its own database, chosen based on specific requirements.
      Message Broker:
      Facilitates communication between microservices through asynchronous messaging.

* 3.  What are Resilience patterns? What is circuit breaker?
      Resilience patterns are design patterns that focus on creating systems that can gracefully handle and recover from failures and disruptions.
      If a system call results in an error, the circuit breaker is opened and does not allow any calls to pass through.

* 4.  Read this article, then list the important questions, then write your answers
    * a. https://www.interviewbit.com/microservices-interview-questions/#main-features-of-microservices
* 5.  how to do load balance in microservice? Write a long Summary by yourself.
    * a. https://www.geeksforgeeks.org/load-balancer-system-design-interview-question/
    * b. https://www.fullstack.cafe/blog/load-balancing-interview-questions
      Service-Side Load Balancing: Each microservice instance registers with a service registry, and the load balancer queries this registry to distribute traffic.
      Service Discovery::
      Service Registry: A central repository that keeps track of available microservice instances and their network locations.
      Load Balancing Algorithms:
         Round Robin: Distributes traffic equally among healthy instances.
         Least Connections: Directs traffic to the instance with the fewest active connections.
      Dynamic Scaling:
         Auto-Scaling: Automatically adjusts the number of microservice instances based on the incoming traffic and resource utilization.
* 6.  How to do service discovery?
      Service Registration:
      Each microservice, when it starts up, registers itself with the service registry.
      Service Query:
      When a microservice needs to communicate with another service, it queries the service registry.
      Dynamic Updates:
      The service registry should support dynamic updates, so if a service goes down or a new service comes up, the registry is updated accordingly.
      Heartbeats and Health Checks:
      To ensure accurate information in the service registry, services often send regular heartbeats or health checks to indicate that they are still alive.
* 7. What are the major components of Kafka?
     Producer:
        Responsibility: Produces and publishes messages (records) to Kafka topics.
        Functionality: Sends messages to topics, which are then stored in Kafka.
     Consumer:
        Responsibility: Subscribes to topics and processes the published messages.
     Broker:
        Responsibility: Manages storage, distribution, and retrieval of messages.
     Topic:
        Responsibility: Logical channel for organizing and categorizing messages
     Partition:
       Responsibility: Divides topics into smaller, manageable units.
       Functionality: Each partition can be hosted on a different broker, allowing for parallelism and scalability.
     ZooKeeper:
        Responsibility: Manages and coordinates the Kafka brokers in a cluster
     Offset:
        Responsibility: Unique identifier assigned to each message in a partition.
     Consumer Group:
        Responsibility: Group of consumers that work together to consume and process messages.
* 8.  What do you mean by a Partition in Kafka?
    A partition is a linearly ordered, immutable sequence of messages.
    Enable Kafka to handle large amounts of data and provide high throughput 
    Kafka topics are divided into multiple partitions and each partition can be hosted on a different broker 
    Data is kept only for a limited time and each partition is ordered.
    Each message within a partition gets an incremental id, called offset.

* 9.  What do you mean by zookeeper in Kafka and what are its uses?
    Zookeeper is used in a distributed system and manages brokers.
    Zookeeper helps in performing leader election for partitions
* 10. Can we use Kafka without Zookeeper?
      With KRaft, it's possible to run Kafka without an external ZooKeeper dependency.
      KRaft provides a self-contained solution for managing the distributed nature of Kafka, reducing the need for a separate ZooKeeper cluster.
* 11. Explain the concept of Leader and Follower in Kafka.
    At any time only one broker can be a leader for a given partition 
    All read and write operations for a partition go through the leader and leader is responsible for handling client requests 
    Followers are replicas of the leader partition and stay in sync with it.
    In-Sync Replicas (ISRs):
        ISRS are a subset of followers that are currently caught up with the leader.
        Only the brokers in the ISR list are eligible to become the new leader if the current leader fails.
      Maintaining ISRs ensures that only replicas that are up-to-date participate in leader election, improving fault tolerance.
12. Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?
      Replication provides a safeguard against data loss in the event of broker failures.
      Replicated partitions enable Kafka to continue serving read and write requests even when some brokers are unavailable.
      In-Sync Replicas (ISRs):
        ISRS are a subset of followers that are currently caught up with the leader.
        Only the brokers in the ISR list are eligible to become the new leader if the current leader fails.
        Maintaining ISRs ensures that only replicas that are up-to-date participate in leader election, improving fault tolerance.    
* 13. What do you understand about a consumer group in Kafka?
      A consumer group consists of multiple consumers that subscribe to the same Kafka topics.
      Consumer groups enable parallel message processing by allowing each consumer within the group to independently process a subset of the partitions in a topic.
      Kafka ensures that each partition in a topic is assigned to only one consumer within a consumer group.
* 14. How do you start a Kafka server?
      (server / broker)$ bin/kafka-server-start.sh config/server.properties
* 15. Tell me about some of the real-world usages of Apache Kafka.
      E-commerce Order Processing:
        Kafka can be used to handle order placement, inventory updates, and order fulfillment.
      Supply Chain Visibility:
        Kafka can be used to provide real-time visibility into inventory, shipments, and logistics.
      Real-time Analytics for Online Retail:
         Online retailers use Kafka for real-time analytics of customer behavior. Clickstream data, product views, and purchase events are streamed through Kafka, enabling businesses to personalize recommendations and improve the customer experience.
      Social Media Data Processing:
         Social media platforms use Kafka to process and analyze vast amounts of data generated by users in real-time. This includes handling tweets, posts, and user interactions to provide trending topics and personalized content.    
* 16. Describe partitioning key in Kafka.
      Key is used to determine the partition to which the message will be assigned
      Kafka uses a partitioning algorithm to determine the partition to which a message will be assigned based on its key. The goal is to ensure that messages with the same key are consistently assigned to the same partition.
* 17.  What is the purpose of partitions in Kafka?
       Partitions enable parallel processing of data. Multiple producers can write to different partitions concurrently, and multiple consumers can read from different partitions simultaneously.
       Kafka guarantees the order of messages within a partition.
* 18. Differentiate between Rabbitmq and Kafka.
      RabbitMQ is well-suited for traditional queuing scenarios, while Kafka is designed for distributed, fault-tolerant, and scalable event streaming applications.
* 19. What are the guarantees that Kafka provides?
      Reliability and Durability:
        Message Persistence: Kafka ensures that messages written to topics are durably stored on disk, preventing data loss even in the event of broker failures.
      Ordered Delivery:
        Ordering within Partitions: Kafka guarantees that messages sent to a particular partition of a topic will be written in the order they are received. This ensures ordered delivery within a partition.
      At-Least-Once Delivery:
        Producers can configure Kafka to require acknowledgment (ack) from brokers after a message is successfully written to a specified number of replicas. This ensures at least once delivery semantics.
      Scalability and Partitioning:
        Kafka achieves scalability by horizontally adding more brokers to the cluster
* 20. What do you mean by an unbalanced cluster in Kafka? How can you balance it?
      An unbalanced cluster in Kafka refers to a situation where the distribution of partitions or data among broker nodes is uneven.
      Partition Reassignment:
        The kafka-reassign-partitions.sh script can be used to generate a plan for reassigning partitions to achieve a more balanced distribution.
      Increase Partition Count:
        Increasing the number of partitions for a topic can help distribute the load more evenly across brokers
* 21. In your recent project, are you a producer or consumer or both?
      E-commerce Order Processing:
            Consumer: When a customer places an order, an event is produced to the order_placement_events topic. Subscribers (consumers) can then process these events to update inventory, trigger order fulfillment, and perform other related actions.
      Supply Chain Visibility:
            inventory_updates and shipment_status_events  
      Social Media Data Processing:
            
* 22. In your recent project, Could you tell me your topic name?
      No. 1 / 2
      E-commerce Order Processing:
        order_placement_events
      
* 23. In your recent project, How many brokers do you have? How many partitions for each topic? How many data for each topic.
      For the order_placement_events topic, we configured it with 5 partitions to parallelize the processing of order placement events efficiently. Each partition was able to handle a substantial load of data, 
        and we ensured that the topic was well-balanced to optimize Kafka's performance. Additionally, we monitored the data size regularly, 
        and during peak times, we processed around 10,000 events per minute to maintain real-time order visibility and quick order fulfillment.
* 24. In your recent project, which team produce what kind of event to you and you producer what kind of events?
      the Analytics and Recommendations team, was responsible for producing events related to customer behavior and interactions on the online platform. 
        We generated events capturing clickstream data, product views, and purchase events
* 25. What is offset?  
      An offset in Kafka is a unique identifier representing the position of a consumer within a partition.
