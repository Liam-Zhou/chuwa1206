## HW50

#Q2. Document the microservice architeture and components/tools/dependencies
- Spring Cloud
- Zuul API Gateway
- Eureka
- Ribbon Load Balancer
- Hystrix Circuit Breaker
- Config Server
- Kafka
- Docker

#Q3. What are Resilience patterns? What is circuit breaker?

Resilience patterns are design strategies used in software development to make applications more robust, fault-tolerant, and resilient to failures, especially in distributed systems where different components and services interact over networks. These patterns help applications to gracefully handle and recover from unexpected issues like network failures, service unavailability, and resource limitations. Common resilience patterns include retry, timeout, and circuit breaker.

The circuit breaker pattern is one of the key resilience patterns. It prevents an application from performing operations that are likely to fail by "breaking" the connection to the failing service.
How Circuit Breaker Works:

1. Closed State: Initially, the circuit breaker is in the Closed state, and operations are allowed. If the number of failures surpasses a predefined threshold within a certain period, the breaker trips, transitioning to the Open state.

2. Open State: In this state, the circuit breaker prevents any operations by failing them immediately, without the operations being executed. This gives the failing system time to recover.

3. Half-Open State: After a predefined "cooldown" period in the Open state, the circuit breaker enters the Half-Open state. Here, a limited number of test operations are allowed to pass through and execute. If these operations are successful, indicating the issue is resolved, the circuit breaker resets back to the Closed state. If these operations fail, the circuit breaker goes back to the Open state.


#Q4. Read this article, then list the important questions, then write your answers https://www.interviewbit.com/microservices-interview-questions/#main-features-of-microservices

1. Write main features of Microservices.
- Decoupling: Within a system, services are largely decoupled. The application as a whole can therefore be easily constructed, altered, and scalable
- Componentization: Microservices are viewed as independent components that can easily be exchanged or upgraded
- Business Capabilities: Microservices are relatively simple and only focus on one service

2. Write main components of Microservices.
- Containers, Clustering, and Orchestration 
- IaC [Infrastructure as Code Conception] 
- Cloud Infrastructure 
- API Gateway 
- Enterprise Service Bus 
- Service Delivery 

#Q5. How to do load balance in microservice? Write a long Summary by yourself.
a. https://www.geeksforgeeks.org/load-balancer-system-design-interview-question/
b. https://www.fullstack.cafe/blog/load-balancing-interview-questions
1. Client-Side Load Balancing
- In this approach, the decision of which service instance to route a request to is made by the client itself, often using a service registry where all service instances are registered.
- Netflix Ribbon is a client-side IPC library that includes built-in support for load balancing. It works well with Eureka, Netflix's service discovery tool.

2. Server-Side Load Balancing
- With server-side load balancing, incoming requests are first received by a load balancer, which then forwards the request to one of the available service instances based on a specified algorithm.
- Traditional hardware or software load balancers (like HAProxy, Nginx) or cloud-based load balancers (like AWS ELB, Azure Load Balancer, Google Cloud Load Balancing) can be used. In the context of Kubernetes, an Ingress Controller can act as a load balancer.

3. API Gateway
- An API Gateway sits between clients and services and can perform load balancing along with other functions like authentication, rate limiting, and request/response transformations.
- Zuul is a popular API Gateway

#Q6. How to do service discovery?
Service discovery allows services to query a central registry to find the network locations of other services they depend on.
There are two main ways of doing service discovery: Client-side Discovery and Server-side Discovery.

1. Client-side Discovery:
- How It Works: In this pattern, each service registers itself with a service registry upon startup, and deregisters upon shutdown. When a service needs to communicate with another service, it queries the service registry, retrieves the available network locations, and then uses a load-balancing algorithm to select a service instance and make the request.
- Tools/Frameworks: Netflix Eureka is a popular example of a tool that supports client-side discovery. Clients using Netflix's Ribbon library can then perform load balancing based on the information from Eureka.

2. Server-side Discovery
- How It Works: In server-side discovery, the client makes a request to a service via a load balancer or an API gateway, which queries the service registry and forwards the request to an available service instance. The client doesn't need to query the service registry directly or handle load balancing.
- Tools/Frameworks: Tools like Netflix Zuul (API Gateway), Kubernetes with its built-in service discovery and load balancing, and AWS Elastic Load Balancer (ELB) can be used to implement server-side discovery.

#Q7. What are the major components of Kafka?
1. Producer: Producers are applications or processes that send (publish) records (messages) to Kafka topics. A producer can choose which topic and partition within the topic to send the records to.
2. Consumer: Consumers are applications or processes that read (subscribe to) records from Kafka topics. Consumers can read records from one or more topics and process them.
3. Broker: Brokers are the servers that make up the Kafka cluster. Each broker is a Kafka server instance that stores data and serves client requests. Brokers are responsible for receiving records from producers, storing them on disk, and serving them to consumers. Brokers also handle tasks like replication, leader election for partitions, and rebalancing of consumers.
4. Topic: A topic is a category or feed name to which records are published by producers. Topics in Kafka are multi-subscriber, meaning they can be consumed by multiple consumers.
5. Partition: Partitions are ordered, immutable sequences of records that are continually appended to within a topic. Each partition is an ordered, immutable sequence of records and is the basic unit of parallelism in Kafka.
6. Zookeeper: Zookeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. Kafka uses Zookeeper to manage cluster metadata and to coordinate the brokers and consumers.
7. Consumer Group: A consumer group consists of one or more consumers that work together to consume a topic. The consumers in a group divide the topic partitions among themselves so that each partition is consumed by exactly one consumer in the group.

#Q8.  What do you mean by a Partition in Kafka?
In Apache Kafka, a partition is a fundamental concept that represents a single unit of storage within a topic. A Kafka topic is divided into one or more partitions to enable distributed storage and parallel processing of data. Each partition is an ordered, immutable sequence of records (messages) that are continually appended to. 

#Q9.  What do you mean by zookeeper in Kafka and what are its uses?
ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.
Key Functionalities of ZooKeeper:
1. Broker Management:ZooKeeper keeps track of the status of Kafka brokers (servers) in the cluster. It knows which brokers are live and participating in the Kafka cluster at any given time.
2. Topic Configuration Storage:Information about topics, such as topic names, the number of partitions for each topic, their replication factor, and other topic-level configurations, is stored in ZooKeeper.
3. Cluster Metadata:ZooKeeper maintains metadata about the Kafka cluster, including which broker is the controller (the broker responsible for administrative operations such as partition leader election).
4. Partition Leadership: ZooKeeper is responsible for leader election for partitions. Each partition of a topic has one leader broker (which handles all read and write requests for that partition) and zero or more follower brokers (which replicate the leader's data). ZooKeeper helps in electing the leader broker for each partition.

#Q10. Can we use Kafka without Zookeeper?
Usually, Kafka relies on ZooKeeper for various functions like broker coordination, leader election, and configuration management. However, as of Kafka 2.8.0 (released in April 2021), it's possible to run Kafka in KRaft mode without ZooKeeper for testing and development purposes. 

#Q11. Explain the concept of Leader and Follower in Kafka.
Each partition of a topic can have multiple replicas distributed across different brokers in the Kafka cluster, but at any given time, one of these replicas is designated as the "Leader," and the rest as "Followers."

1. Leader:
- The Leader replica for a partition is responsible for handling all read and write requests for that partition. When producers send messages to a partition, they are actually sent to the leader replica, regardless of which broker hosts it.
- The leader also coordinates updates to the partition, ensuring that data is consistent and in order across all replicas.
- If the leader replica fails (e.g., if the broker hosting it goes down), a new leader is elected from the set of available follower replicas.

2. Followers:
- Follower replicas do not serve client requests directly. Instead, their primary role is to replicate the messages from the leader replica to ensure data redundancy and fault tolerance.
- Followers pull messages from the leader, staying as up-to-date as possible with the leader's log of messages. This way, if the leader fails, one of the followers can quickly be promoted to the new leader with minimal loss of data.
- Followers also participate in the process of "in-sync replicas" (ISR), which is a subset of replicas considered to be sufficiently up-to-date with the leader. Only replicas in the ISR can be elected as a new leader.

#Q12. Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?
1. Importance of Topic Replication:
- Fault Tolerance: Replication ensures that even if a broker fails, the data in its partitions are available on other brokers. This prevents data loss and allows Kafka to continue operations without interruption.

- High Availability: With replicas, Kafka can automatically failover to a follower replica if a leader replica fails, minimizing downtime. This ensures that the topic remains available for both producers and consumers.

- Load Balancing: Read operations can be distributed across multiple replicas (though writes always go through the leader), balancing the load and improving performance.

- Durability: Replication increases the durability of data, ensuring that even in the case of hardware failures, the data is not lost and can be recovered from other replicas.

2. ISR stands for In-Sync Replicas. It is a subset of replicas for a partition that are considered to be sufficiently up-to-date with the leader replica. 

#Q13. What do you understand about a consumer group in Kafka?
Consumers that are part of the same application and therefore performing the same "logical job" can be grouped together as a Kafka consumer group.

A topic usually consists of many partitions. These partitions are a unit of parallelism for Kafka consumers. The benefit of leveraging a Kafka consumer group is that the consumers within the group will coordinate to split the work of reading from different partitions.

#Q14. How do you start a Kafka server?
1. Start Zookeeper: 
```
bin/zookeeper-server-start.sh config/zookeeper.properties

```
2. Start Kafka Server
```
bin/kafka-server-start.sh config/server.properties

```

#Q15. Tell me about some of the real-world usages of Apache Kafka.
Many organizations use Kafka for aggregating logs from different services and components within their infrastructure. Kafka serves as a central hub for log data, which can then be processed, analyzed, or stored in various logging and monitoring systems.

#Q16. Describe partitioning key in Kafka.
Each event message contains an optional key and a value.
In case the key (key=null) is not specified by the producer, messages are distributed evenly across partitions in a topic. This means messages are sent in a round-robin fashion (partition p0 then p1 then p2, etc... then back to p0 and so on...).
If a key is sent (key != null), then all messages that share the same key will always be sent and stored in the same Kafka partition. 

#Q17. What is the purpose of partitions in Kafka?
1. Scalability: Partitions allow Kafka to split the data of a topic across multiple brokers in the cluster. This distribution enables parallel processing, significantly increasing the throughput of the system. 
2. Fault Tolerance:  If a broker fails, other brokers that have replicas of its partitions can take over, ensuring that the data remains available and the system continues to operate without data loss.
3. Performance Optimization: Partitions enable Kafka to support consumer groups effectively. 

#Q18. Differentiate between Rabbitmq and Kafka.
RabbitMQ is more traditionally used as a flexible message broker with strong support for message queuing and routing, while Kafka is optimized for high-throughput, scalable, and durable storage of stream data. 

#Q19. What are the guarantees that Kafka provides?
1. Messages are appended to a topic-partition in the order they are sent
2. Consumers read messages in the order stored in a topic-partition
3. With a replication factor of N, producers and consumers can tolerate up to N-1 brokers being down
4. As long as the number of partitions remains constant for a topic, the same key will always go to the same partition.

#Q20. What do you mean by an unbalanced cluster in Kafka? How can you balance it?
An unbalanced Kafka cluster refers to a situation where the distribution of partitions, leaders, or workload across the brokers in the cluster is uneven. There are a few ways to balance it:
1. Manual Reassignment of Partitions
2. Automated Rebalancing Tools
3. Monitoring and Adjusting Replication Factors

#Q21. In your recent project, are you a producer or consumer or both?
#Q22. In your recent project, Could you tell me your topic name?
#Q23. In your recent project, How many brokers do you have? How many partitions for each topic? How many data for each topic.
#Q24. In your recent project, which team produce what kind of event to you and you producer what kind of events?
#Q25. What is offset?
Offset is basically the index of a partition.