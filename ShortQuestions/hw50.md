## What are Resilience patterns? What is circuit breaker?

Resilience Patterns:
Resilience patterns are design principles and practices that aim to improve a system's ability to recover from failures and adapt to changing conditions. 

Retry Mechanism: Automatically retrying failed operations to give the system a chance to recover.
Timeouts: Setting time limits for operations to prevent them from hanging indefinitely.

Circuit Breaker: Preventing the system from continuously trying to perform an operation that is likely to fail.

## Read this article, then list the important questions, then write your answers

Main features of Microservices:

Decoupling: Within a system, services are largely decoupled. The application as a whole can therefore be easily constructed, altered, and scalable
Componentization: Microservices are viewed as independent components that can easily be exchanged or upgraded
Business Capabilities: Microservices are relatively simple and only focus on one service
Team autonomy: Each developer works independently of each other, allowing for a faster project timeline
Continuous Delivery: Enables frequent software releases through systematic automation of software development, testing, and approval
Responsibility: Microservices are not focused on applications as projects. Rather, they see applications as products they are responsible for
Decentralized Governance: Choosing the right tool according to the job is the goal. Developers can choose the best tools to solve their problems
Agility: Microservices facilitate agile development. It is possible to create new features quickly and discard them again at any time.

Components of Microservices:

Containers, Clustering, and Orchestration 
IaC [Infrastructure as Code Conception] 
Cloud Infrastructure 
API Gateway 
Enterprise Service Bus 
Service Delivery 

What are the benefits and drawbacks of Microservices?

Benefits: 

Self-contained, and independent deployment module. 
Independently managed services.   
In order to improve performance, the demand service can be deployed on multiple servers.   
It is easier to test and has fewer dependencies.  
A greater degree of scalability and agility.   
Simplicity in debugging & maintenance.  
Better communication between developers and business users.   
Development teams of a smaller size.

Drawbacks: 

Due to the complexity of the architecture, testing and monitoring are more difficult.  
Lacks the proper corporate culture for it to work.   
Pre-planning is essential.  
Complex development.  
Requires a cultural shift.  
Expensive compared to monoliths.   
Security implications. 
Maintaining the network is more difficult.  

Explain the working of Microservice Architecture:

Clients: Different users send requests from various devices. 
Identity Provider: Validate a user's or client's identity and issue security tokens. 
API Gateway: Handles the requests from clients. 
Static Content: Contains all of the system's content. 
Management: Services are balanced on nodes and failures are identified. 
Service Discovery: A guide to discovering the routes of communication between microservices. 
Content Delivery Network: Includes distributed network of proxy servers and their data centers. 
Remote Service: Provides remote access to data or information that resides on networked computers and devices. 

Write difference between Monolithic, SOA and Microservices Architecture:

Monolithic Architecture: It is "like a big container" where all the software components of an application are bundled together tightly.  It is usually built as one large system and is one code-base. 

SOA (Service-Oriented Architecture): It is a group of services interacting or communicating with each other. Depending on the nature of the communication, it can be simple data exchange or it could involve several services coordinating some activity.   

Microservice Architecture: It involves structuring an application in the form of a cluster of small, autonomous services modeled around a business domain. The functional modules can be deployed independently, are scalable, are aimed at achieving specific business goals, and communicate with each other over standard protocols. 

Explain spring cloud and spring boot:

Spring Cloud: In Microservices, the Spring cloud is a system that integrates with external systems. This is a short-lived framework designed to build applications quickly. It contributes significantly to microservice architecture due to its association with finite amounts of data processing.

Spring Boot: Spring Boot is an open-sourced, Java-based framework that provides its developers with a platform on which they can create stand-alone, production-grade Spring applications. In addition to reducing development time and increasing productivity, it is easily understood.  

What is the role of actuator in spring boot?

A spring boot actuator is a project that provides restful web services to access the current state of an application that is running in production. In addition, you can monitor and manage application usage in a production environment without having to code or configure any of the applications.

What issues are generally solved by spring clouds?

Complicated issues caused by distributed systems: This includes network issues, latency problems, bandwidth problems, and security issues. 
Service Discovery issues: Service discovery allows processes and services to communicate and locate each other within a cluster. 
Redundancy issues: Distributed systems can often have redundancy issues. 
Load balancing issues: Optimize the distribution of workloads among multiple computing resources, including computer clusters, central processing units, and network links. 
Reduces performance issues: Reduces performance issues caused by various operational overheads. 

Write the fundamental characteristics of Microservice Design:

Based on Business Capabilities: Services are divided and organized around business capabilities. 
Products not projects: A product should belong to the team that handles it.  
Essential messaging frameworks: Rely on functional messaging frameworks: Eliminate centralized service buses by embracing the concept of decentralization.  
Decentralized Governance: The development teams are accountable for all aspects of the software they produce.  
Decentralized data management: Microservices allow each service to manage its data separately.  
Automated infrastructure: These systems are complete and can be deployed independently.   
Design for failure: Increase the tolerance for failure of services by focusing on continuous monitoring of the applications. 

Explain how independent microservices communicate with each other:

HTTP/REST with JSON or binary protocol for request-response 
Websockets for streaming.  
A broker or server program that uses advanced routing algorithms. (Event Driven)

What is the main role of docker in microservices?

Docker generally provides a container environment, in which any application can be hosted. This is accomplished by tightly packaging both the application and the dependencies required to support it. These packaged products are referred to as Containers, and since Docker is used to doing that, they are called Docker containers. Docker, in essence, allows you to containerize your microservices and manage these microservices more easily.

## How to do load balance in microservice? Write a long Summary by yourself.

Load balancing in a microservices architecture is essential to ensure that the traffic and workload are distributed evenly across multiple instances of microservices. This helps in optimizing resource utilization, improving system performance, and ensuring high availability.

## How to do service discovery?

It involves dynamically discovering and locating services at runtime so that applications can effectively communicate with each other.

## What are the major components of Kafka?

Producer: The producer is responsible for publishing messages to Kafka topics. It sends records to one or more Kafka brokers, which then stores and distributes the records to the appropriate partitions.

Broker: Kafka brokers are servers that store and manage the topic partitions. They are responsible for receiving messages from producers, storing them on disk, and serving them to consumers. Brokers work together to form a Kafka cluster.

Consumer: Consumers subscribe to one or more Kafka topics and process the records produced to those topics. Consumers can be part of a consumer group, enabling parallel processing of records across multiple consumers for scalability.

Topic: A topic is a logical channel or feed name to which records are published by producers and from which records are consumed by consumers. Topics provide a way to organize and categorize the streams of records in Kafka.

Partition: Each topic is divided into partitions, which are the basic unit of parallelism and distribution in Kafka. Partitions allow Kafka to scale horizontally by distributing the load across multiple broker nodes. Each partition is an ordered, immutable sequence of records.

Consumer Groups: Consumers can be organized into consumer groups, where each group processes a subset of the partitions for a topic. Consumer groups enable parallel processing and load balancing across multiple consumers.

Offset: An offset is a unique identifier assigned to each record within a partition. Consumers use offsets to keep track of the last record they have consumed. Offsets are stored in a topic called "__consumer_offsets" and enable consumers to resume processing from where they left off after a restart.

## What do you mean by a Partition in Kafka?

Partition: Each topic is divided into partitions, which are the basic unit of parallelism and distribution in Kafka. Partitions allow Kafka to scale horizontally by distributing the load across multiple broker nodes. Each partition is an ordered, immutable sequence of records.

## What do you mean by zookeeper in Kafka and what are its uses?

Distributed Coordination: ZooKeeper is designed to provide a distributed coordination service for distributed systems. It helps maintain configuration information, synchronize distributed processes, and manage group memberships in a reliable and fault-tolerant manner.

Consensus and Atomic Broadcast: ZooKeeper uses a consensus algorithm to ensure that a majority of nodes agree on the state of the system. This is crucial for achieving consistency in distributed environments.

Uses of ZooKeeper in Kafka: 

1. Metadata Management: ZooKeeper is used in Kafka to manage and store metadata about the Kafka cluster. This includes information about brokers, partitions, topics, and their configurations. Kafka brokers register themselves in ZooKeeper, and clients (producers and consumers) can discover the current state of the Kafka cluster by querying ZooKeeper.

2. Leader Election: Kafka partitions are distributed across multiple broker nodes. Each partition has a leader that is responsible for handling reads and writes. ZooKeeper is used to elect a leader for each partition. In the event of a broker failure, ZooKeeper helps in the re-election of leaders to maintain the availability of partitions.

3. Configuration Management: Kafka uses ZooKeeper to store and manage configuration information, such as broker settings and topic configurations. This allows Kafka to maintain a consistent and centralized configuration across the distributed cluster.

4. Broker Registration: Kafka brokers register themselves in ZooKeeper, making it easy for other components (producers, consumers) to discover the available brokers and their addresses. This dynamic discovery is essential for handling changes in the cluster, such as broker additions or removals.

5. Consumer Group Coordination: In Kafka, consumer groups are used for parallel processing and load balancing. ZooKeeper assists in managing the membership and coordination of consumer groups, helping consumers distribute the partitions they are responsible for among themselves.

## Can we use Kafka without Zookeeper?

Yes. The Kafka community has introduced the KRaft mode as an alternative to ZooKeeper for metadata management and coordination. KRaft is a consensus protocol that allows Kafka brokers to handle their metadata and coordination internally without relying on ZooKeeper.

In KRaft mode, Kafka brokers form a self-contained, distributed consensus group for managing metadata. This eliminates the need for a separate ZooKeeper ensemble dedicated to Kafka. It's important to note that KRaft is an optional mode, and users can still choose to run Kafka with ZooKeeper if they prefer.

## Explain the concept of Leader and Follower in Kafka:

Leader: For each partition, one replica is designated as the Leader. The Leader is responsible for handling all reads and writes for that partition.

Follower: Replicas that are not the Leader for a partition are referred to as Followers. Followers replicate the data from the Leader.

## Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?

Replication ensures that copies (replicas) of a Kafka topic's partitions are maintained across multiple broker nodes. Each partition has one leader and multiple followers (replicas). The In-Sync Replicas (ISRs) play a crucial role in this replication mechanism.

In-Sync Replicas (ISRs) are a subset of replicas for a partition that are currently caught up with the leader's log. In other words, ISRs are the replicas that have replicated the latest data and are in sync with the leader.

## What do you understand about a consumer group in Kafka?

In Apache Kafka, a consumer group is a logical grouping of Kafka consumers that work together to consume and process messages from one or more Kafka topics. Consumer groups provide a scalable and parallelized way to process data, allowing multiple consumers to work together to read and process messages from different partitions of a topic.

## How do you start a Kafka server?

1. Start ZooKeeper 
2. Start Kafka Server, Open a new terminal window, navigate to the Kafka home directory, and start the Kafka server.

## Tell me about some of the real-world usages of Apache Kafka.

Messaging System: Kafka is frequently used as a high-throughput, fault-tolerant messaging system for decoupling producers and consumers. It allows different parts of a system to communicate asynchronously, facilitating scalable and resilient architectures.

Log Aggregation: Kafka's durability and ability to handle high volumes of data make it suitable for log aggregation. It can collect, store, and forward logs from various applications and services, providing a centralized platform for log analysis and monitoring.

## Describe partitioning key in Kafka.

When producers send messages to a Kafka topic, each message is associated with a key. The partitioning key is used to determine which partition within the topic the message will be assigned to.

## What is the purpose of partitions in Kafka?

Parallel Processing: Kafka topics are divided into multiple partitions, and each partition can be processed independently. This enables parallel processing of messages, making it possible for multiple consumers to work simultaneously on different partitions of the same topic. This parallelism enhances the throughput and efficiency of data processing.

Horizontal Scalability: Partitions enable horizontal scalability by allowing Kafka to distribute and parallelize the storage and processing of data across multiple nodes (broker servers). Each partition acts as an independent unit of parallelism, allowing Kafka to handle large volumes of data and requests in a distributed manner.

## Differentiate between Rabbitmq and Kafka?

RabbitMQ and Apache Kafka are both popular distributed messaging systems, but they are designed for different use cases and scenarios.

RabbitMQ is a traditional message broker that follows a message queue model. It excels in scenarios where message ordering, guaranteed delivery, and complex routing are important. RabbitMQ is well-suited for traditional enterprise messaging systems, task queues, and RPC scenarios.

Kafka is a distributed streaming platform designed for high-throughput, fault-tolerant, and scalable event streaming. It follows a distributed commit log model and is particularly well-suited for scenarios involving real-time data processing, log aggregation, data integration, and event sourcing.

Message Model: RabbitMQ follows a message queue model, while Kafka follows a distributed commit log model for event streaming.

Use Cases: RabbitMQ is suitable for traditional messaging scenarios, whereas Kafka excels in real-time event streaming and processing.

Message Persistence: Both systems support message persistence, but Kafka's durability is designed for scenarios with a focus on distributed commit logs.

Scalability: Kafka is known for its horizontal scalability and is designed to handle large-scale data streaming, making it suitable for high-throughput scenarios.

Consumer Model: RabbitMQ supports competing consumers, while Kafka supports both point-to-point and publish-subscribe patterns with the ability to distribute partitions across consumers.

Ordering: RabbitMQ guarantees ordering within a single queue, while Kafka guarantees ordering within a partition.

Ecosystem: Both RabbitMQ and Kafka have rich ecosystems with various client libraries, connectors, and integrations, catering to different programming languages and frameworks.

## What are the guarantees that Kafka provides?

Publish-Subscribe Model: Kafka follows a publish-subscribe model, where producers publish messages to topics, and consumers subscribe to topics to receive those messages. This model allows multiple consumers to independently process the same data stream.

Durability: Kafka is designed to be durable, meaning that once a message is written to a topic, it is persisted on disk and can be retrieved later, even in the face of broker restarts or failures. This durability ensures that data is not lost.

Partitioning and Scalability: Kafka allows topics to be divided into partitions, enabling horizontal scalability. Each partition is an independent unit of parallelism, and Kafka distributes partitions across multiple broker nodes. This ensures that Kafka can handle large volumes of data and scale horizontally.

Ordering Within a Partition: Kafka provides strong ordering guarantees within a partition. Messages written to a partition are appended in the order they are received. Consumers reading from a partition will process messages in the same order.

At-Least-Once Delivery: Kafka provides an "at-least-once" delivery guarantee. This means that a message is guaranteed to be delivered to at least one consumer in the system. In the event of failures, a message may be redelivered, leading to potential duplicates.

Consumer Offsets and Exactly-Once Semantics: Kafka allows consumers to commit their offsets, representing the position in the log where they have consumed messages. By committing offsets, consumers can ensure that they do not reprocess messages in the event of failures. With appropriate configurations and use of idempotent producers, Kafka can provide "exactly-once" semantics for message delivery.

Fault Tolerance: Kafka is designed to be fault-tolerant. It achieves fault tolerance by replicating data across multiple broker nodes. Each partition has a leader and multiple replicas. If a broker or partition becomes unavailable, one of the replicas can be elected as the new leader, ensuring continuous availability.

Scalable and Efficient Reads/Writes: Kafka is capable of handling high-throughput reads and writes, making it suitable for scenarios with demanding performance requirements. Its design allows for efficient data processing and distribution of workloads.

Retention Policies: Kafka allows users to set retention policies for topics, defining how long messages should be retained in a topic. This feature supports use cases where historical data needs to be preserved or where data should be retained for specific compliance requirements.

##  What do you mean by an unbalanced cluster in Kafka? How can you balance it?

In Apache Kafka, an unbalanced cluster refers to a situation where the workload or data distribution across the Kafka brokers (nodes) is uneven. An unbalanced cluster can lead to performance issues, reduced throughput, and inefficient resource utilization. 

Balancing a Kafka cluster involves redistributing partitions and workloads to ensure a more even distribution of data and processing across all brokers.

## What is offset?

In Apache Kafka, an offset is a unique identifier that represents the position of a consumer within a particular partition of a topic. Each message within a partition is assigned a sequential offset starting from 0 for the earliest message. As consumers read and process messages, they keep track of their progress by maintaining the offset.

