# HW14

## 1. What are Resilience patterns? What is circuit breaker?

Resilience patterns help software handle failures gracefully, enabling continuous operation even when issues arise. These patterns act as safety nets, catching and managing errors to avoid complete system failure. Key resilience patterns include:

- **Retry**: Re-attempting a failed request in hopes it succeeds later.
- **Circuit Breaker**: Ceasing requests to a failing service to allow recovery, akin to an electrical circuit breaker that prevents overload by cutting power.
- **Timeout**: Abandoning a request if it takes too long, preventing indefinite waiting.
- **Bulkhead**: Isolating application parts so if one fails, the rest continue working.
- **Fallback**: Employing an alternative plan or response upon failure.
- **Rate Limiting/Throttling**: Managing service traffic to prevent overload.
- **Cache**: Temporarily storing frequently accessed data to enhance speed and reduce load.

The **Circuit Breaker** pattern specifically acts like an electrical circuit breaker for web services. It "trips" to halt requests to a service if the service fails, preventing further strain. It then periodically checks if the service has recovered before resuming requests, helping maintain system stability and prevent cascading failures.

## 2. Write difference between Monolithic, SOA, and Microservices Architecture.

### Monolithic Architecture:

- **All-in-One**: The application's functionalities are bundled into a single package, resembling a single, large LEGO model with all pieces glued together.
- **Simple to Start**: Initially easy to develop and deploy due to its unified nature.
- **Hard to Change**: As the application grows, modifications or feature additions become cumbersome, requiring redeployment of the entire application for updates.
- **Scaling Challenges**: Scaling involves duplicating the entire application, not just specific busy parts.

### SOA (Service-Oriented Architecture):

- **Divided by Function**: Applications are divided into services based on functionality, resembling several smaller LEGO models each representing a different function.
- **Reusable Services**: These services can be reused across different application parts or even across different applications.
- **Medium Complexity**: Offers more flexibility than monolithic architectures by allowing independent service updates, though service communication management can be complex.
- **Better Scaling than Monolithic**: Allows separate scaling of application parts, albeit with some communication overhead.

### Microservices Architecture:

- **Very Fine Division**: The application is decomposed into many small services, each performing a specific function, akin to a vast collection of tiny LEGO models each with its own task.
- **Highly Flexible and Scalable**: Individual services can be updated, added, or scaled independently, enhancing agility.
- **Complex to Manage**: Coordinating numerous small components and ensuring seamless interaction can be challenging.
- **Best for Large Teams and Applications**: Its complexity is justified for large, complex applications, enabling simultaneous work on different services by different teams.

## 3. Explain spring cloud and spring boot.

### Spring Boot

- **What It Is**: A framework for easily creating stand-alone, production-grade Spring-based applications.
- **Key Point**: Simplifies the development process by automating configuration, enabling applications to be launched with minimal setup.
- **Benefits**: Facilitates the creation of microservices and standalone applications, reducing the need for external web servers through embedded server options.

### Spring Cloud

- **What It Is**: A set of tools for developing cloud-based microservices.
- **Key Point**: Facilitates service discovery, configuration management, and resilience patterns, supporting microservices architecture.
- **Benefits**: Offers patterns for service discovery, distributed configuration, and fault tolerance, easing the development and management of cloud-native applications.

## 4. Explain how independent microservices communicate with each other.

Microservices communicate through mechanisms like:

- **HTTP/REST with JSON or binary protocols** for synchronous request-response interactions.
- **Websockets** for real-time, bidirectional streaming.
- **Message Brokers** (e.g., RabbitMQ, Kafka) for asynchronous message passing, allowing services to publish and subscribe to messages without direct coupling.

These communication methods support decoupling, scalability, and resilience in microservices architectures.

## 5. How to do load balancing in microservices?

Load balancing can be achieved through:

### 1. Client-Side Load Balancing

- Clients select the target service instance based on available services, often employing simple strategies like round-robin.

### 2. Server-Side Load Balancing

- A dedicated load balancer (e.g., Nginx, HAProxy) distributes incoming requests across multiple service instances to even out the load.

### 3. API Gateway

- Acts as a single entry point for all client requests, routing them to the appropriate services and may include load balancing functionality.

### 4. Service Mesh

- A network layer that automatically manages service communication, including load balancing, across all microservices.

## 6. How to do service discovery?

Service discovery mechanisms include:

1. **Service Registry**: Services register their location upon startup, allowing other services to discover and communicate with them.
2. **Client-Side Discovery**: Clients query the service registry and select an instance for communication.
3. **Server-Side Discovery**: A server or API gateway queries the registry and directs the client to an appropriate service instance.
4. **Dynamic Registration and Deregistration**: Services dynamically register with the registry and periodically confirm their availability.
5. **Health Checking**: Regular checks ensure only available services are discoverable.

## 7. What are the major components of Kafka?

- **Broker**: Handles messages storage and distribution.
- **Producer**: Sends messages to Kafka topics.
- **Consumer**: Retrieves messages from subscribed topics.
- **Topic**: Organizes messages into categories.
- **Partition**: Splits topics for parallel processing.
- **Zookeeper**: Manages Kafka cluster coordination and configuration.

## 8. What do you mean by a Partition in Kafka?

A partition is a segment within a Kafka topic that allows for the parallel processing of messages, enhancing scalability and fault tolerance by distributing messages across multiple servers.

## 9. What do you mean by zookeeper in Kafka and what are its uses?

Zookeeper in Kafka is used for managing and coordinating Kafka broker nodes within the cluster. It handles tasks like leadership election for partitions and cluster membership, ensuring consistent configuration across the cluster.

## 10. Can we use Kafka without Zookeeper?

While Kafka historically relied on Zookeeper for cluster coordination and configuration management, newer Kafka versions (post KIP-500) aim to remove this dependency by incorporating these functionalities directly into Kafka, enabling simpler deployment and management.

## 11. Explain the concept of Leader and Follower in Kafka.

In Kafka, each partition has a designated leader broker that handles all read and write requests for the partition, while follower brokers replicate the leader's data to ensure high availability and fault tolerance. Followers take over as leaders if the current leader fails.

## 12. Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?

Topic replication in Kafka ensures data availability and durability across multiple brokers, protecting against data loss. ISR (In-Sync Replicas) refers to the set of follower partitions that are fully synchronized with the leader partition, ensuring consistency and reliability in the event of a broker failure.

## 13. What do you understand about a consumer group in Kafka?

A consumer group in Kafka is a collection of consumers that jointly consume data from one or more topics, where each consumer within the group reads from a unique partition. This model enables parallel processing and scalable consumption of topic data.

## 14. How do you start a Kafka server?

Starting a Kafka server typically involves initiating the Zookeeper service (if required) and the Kafka broker using provided scripts from the Kafka distribution, ensuring proper configuration for both services to facilitate communication and management within the Kafka cluster.

## 15. Tell me about some of the real-world usages of Apache Kafka.

Apache Kafka is used in a variety of real-world applications, including:

- Building real-time streaming data pipelines that reliably process streams of data.
- Aggregating logs from different services for centralized processing.
- Implementing event sourcing patterns to maintain a record of changes to application state.
- Tracking user or system activities for analytics and monitoring.
- Collecting operational metrics for real-time monitoring and alerting.

## 16. Describe partitioning key in Kafka.

The partitioning key in Kafka is a value used by producers to determine the specific partition within a topic where a message should be sent. This mechanism allows for the consistent routing of messages to partitions, enabling orderly processing and the possibility of key-based message grouping.

## 17. What is the purpose of partitions in Kafka?

Partitions in Kafka enable the parallel processing of data by dividing a topic into multiple segments. This allows multiple consumers to read concurrently from different partitions, increasing throughput and scalability.

## 18. Differentiate between Rabbitmq and Kafka.

- **RabbitMQ** specializes in advanced message queuing with features like message acknowledgment, routing, and delivery confirmations, targeting scenarios requiring complex message delivery patterns.
- **Kafka** is optimized for high-throughput, persistent message storage and streaming data scenarios, focusing on the durable and scalable distribution of large volumes of data.

## 19. What are the guarantees that Kafka provides?

Kafka guarantees that:

- Messages within a partition are ordered and immutable.
- Messages sent by a producer to a specific topic partition will be appended in the order sent.
- Data is replicated across multiple brokers for fault tolerance, ensuring no loss of messages even in the event of broker failures.

## 20. What do you mean by an unbalanced cluster in Kafka? How can you balance it?

An unbalanced cluster in Kafka occurs when the distribution of partitions across brokers is uneven, leading to disproportionate load and resource usage. Rebalancing can be achieved by redistributing partitions across the brokers more evenly, using Kafka's built-in partition reassignment tools to optimize load distribution and performance.