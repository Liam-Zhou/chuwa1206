# Homework 16

- HW50 Microservices

## What are Resilience patterns? What is a circuit breaker?

- Resilience Patterns: Design patterns or strategies implemented within software systems to ensure that the system remains functional and responsive in the face of failures or unexpected conditions. E.g. Retry, Circuit Breaker, Bulkhead, Timeout

- Circuit Breaker: Monitoring for failures and opening the circuit to prevent further calls to a failing component, thus allowing it time to recover.

## Important Questions of Microservices

### Main Features

- Decoupling

- Componentization

- Business Capabilities

- Team Autonomy

- Continuous Delivery

- Responsibility

- Decentralized Governance

- Agility

### Main Components

- Containers, Clustering, and Orchestration

- IaC(Infrastructure as Code Conception)

- Cloud Infrastructure

- API Gateway

- Enterprise Service Bus

- Service Delivery

### Pros and Cons

#### Benefits

- Decoupled, independent deployment and management

- A Greater degree of scalability and agility

- Simplicity in debugging and maintenance

- Better communication between developers and business users

- Development teams of smaller size

- Easier to test with fewer dependencies

#### Drawbacks

- More complex architecture and development

- Expensive compared to monoliths

- Security Implications

## Load balance in Microservice?

- A load balancer **enables elastic scalability** which improves the performance and throughput of data. It allows you to keep many copies of data (redundancy) to ensure the availability of the system. **In case a server goes down** or fails you’ll have the backup to restore the services. 
- Load balancers can be placed at any software layer.
- Many companies use both hardware and software to implement load balancers, depending on the different scale points in their system.

## How to do service discovery?

- Popular tools and frameworks for implementing service discovery include Consul, etc, ZooKeeper, Kubernetes (with its service discovery mechanisms), and Netflix Eureka. These tools provide features such as **service registration, querying, health checking, and dynamic configuration management**, making it easier to build and manage distributed systems.

## What are the major components of Kafka?

- Producer: applications that send data into topics

- Consumer: applications that read data from Kafka topics
  
  - Consumer Group: Consumer groups are logical groupings of consumers that cooperate to consume messages from topics.

- Topic: Kafka topics can contain any kind of message in any format, and the sequence of all these messages is called a data stream.
  
  - Partitions: Topics are divided into partitions, which are ordered and immutable sequences of messages.

- ZooKeeper: maintains information about Kafka brokers, topics, partitions, and consumer groups.

## What do you mean by a Partition in Kafka?

- Topics are broken down into many partitions. A single topic may have more than one partition, it is common to see topics with 100 partitions.

- The number of partitions of a topic is specified at the time of topic creation. Partitions are numbered starting from `0` to `N-1`, where `N` is the number of partitions. 

## What do you mean by Zookeeper in Kafka and what are its uses?

- Zookeeper manages brokers(keeps a list of them)

- Zookeeper helps in performing leader elections for partitions

- Zookeeper sends notifications to Kafka in case of changes(e.g. new topic, broker dies, broker comes up, delete topics, etc.)

## Can we use Kafka without Zookeeper?

- Kafka 2.x can't work without Zookeeper

- Kafka 3.x can work without Zookeeper(KIP-500) -> using Kafka Raft

- Kafka 4.x doesn't have Zookeeper

## Explain the concept of Leader and Follower in Kafka

- At any time only one broker can be a leader for a given partition

- Producers can only send data to the broker who is the leader of a partition

- The other brokers will replicate the data, therefore, each partition has one leader and multiple in-sync replica(Follower)

## Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?

- Topics should have a replication factor>1, so if a broker is down, another broker can serve the data

- Producers can only send data to the broker who is the leader of a partition

- The other brokers will replicate the data, therefore, each partition has one leader and multiple in-sync replicas (ISR)

## What do you understand about a consumer group in Kafka?

- All the consumers in an application read data as a consumer group

- Each consumer within a group reads from exclusive partitions

## How do you start a Kafka server?

- Firstly, we extract Kafka once we have downloaded the most recent version. We must make sure that our local environment has Java 8+ installed to run Kafka.

- The following commands must be done to start the Kafka server and ensure that all services are started in the correct order:

- Start the ZooKeeper service by doing the following:

```plaintext
$bin/zookeeper-server-start.sh config/zookeeper.properties
```

- To start the Kafka broker service, open a new terminal and type the following commands:

```plaintext
$ bin/kafka-server-start.sh config/server.properties
```

## Tell me about some of the real-world usages of Kafka

- **Uber** uses Kafka extensively in their real-time pricing pipeline. Kafka is the backbone through which a significant proportion of the events are communicated to the different stream processing calculations. The speed and flexibility of Kafka allow Uber to adjust their pricing models to the constantly evolving events in the real world (number of available drivers and their position, users and their position, weather events, other events), and bill users the right amount to manage offer and demand.

- **Netflix** has integrated Kafka as the core component of its data platform. They refer to it internally as their Keystone data pipeline. As part of Netflix's Keystone, Kafka handles billions of events a day. Just to give an idea about the huge amount of data that Kafka can handle, Netflix sends about 5 hundred billion events and 1.3 petabytes of data per day into Kafka.

## Describe the partitioning key in Kafka

- Kafka will use a key hashing algorithm to map a partitioning key to a partition.

- The partitioning key will determine which partition should the record be sent to.

## What is the purpose of partitions in Kafka?

- scalability: Partitions allow Kafka to scale horizontally across multiple brokers (servers).

- parallelism: Partitions enable parallel processing of messages by allowing multiple consumers within a consumer group to read from different partitions concurrently.

- fault tolerance: If a broker fails or becomes unavailable, Kafka can continue to serve messages from the replicas stored on other brokers.

- ordering guarantees: Within a single partition, Kafka guarantees strict ordering of messages.

- retention policies: Each partition can have its own retention configuration, specifying how long messages are retained in the partition before they are deleted. This enables fine-grained control over data retention and helps manage storage usage within the Kafka cluster.

## Differentiate between RabbitMQ and Kafka

|                  | RabbitMQ                                                              | Kafka                                                                                                    |
| ---------------- | --------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- |
| Architecture     | uses traditional message queue model                                  | uses distributed partition-based stream processing model                                                 |
| Message handling | deletes messages after they're consumed. Supports message priorities. | Consumers track message retrieval with an offset. Kafka deletes messages after a certain amount of time. |
| Performance      | low latency                                                           | real-time transmission                                                                                   |
| Protocols        | support legacy protocols                                              | TCP for data transmission                                                                                |

## What are the guarantees that Kafka provides?

- Messages are appended to a topic-partition **in the order** they are sent

- ﻿﻿Consumers read messages **in the order** stored in a topic-partition

- ﻿﻿With a replication factor of N, producers, and consumers can tolerate up to N-I brokers being down

- ﻿﻿This is why a replication factor of 3 is a good idea:
  
  - ﻿﻿Allows for one broker to be taken down for maintenance
  
  - ﻿﻿Allows for another broker to be taken down unexpectedly
  
  - ﻿﻿As long as the number of partitions remains constant for a topic (no new partitions), the same key will always go to the same partition

## What is offset?

- Each message within a partition gets an incremental ID, which is called offset.
